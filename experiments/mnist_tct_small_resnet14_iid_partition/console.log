===== MNIST_TCT_SMALL_RESNET14_IID_PARTITION =====
===== MNIST_TCT_SMALL_RESNET14_IID_PARTITION =====
===== MNIST_TCT_SMALL_RESNET14_IID_PARTITION =====
client 0 train samples 6000
client 1 train samples 6000
client 2 train samples 6000
client 3 train samples 6000
client 4 train samples 6000
client 5 train samples 6000
client 6 train samples 6000
client 7 train samples 6000
client 8 train samples 6000
client 9 train samples 6000
val samples--------- 1000
test samples-------- 9000
===================== Start Stage-1 =====================
len(client_models)=10
len(train_loaders)=10
opt[0]=SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.01
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
001 == clients == 0.245 train loss 0.512 | test loss 0.564 | train acc 0.822 | test acc 0.822    == global model ==  train loss 0.888 | test loss 0.817 | train acc 0.621 | test acc 0.655 
002 == clients == 0.144 train loss 0.179 | test loss 0.249 | train acc 0.937 | test acc 0.913    == global model ==  train loss 0.100 | test loss 0.123 | train acc 0.966 | test acc 0.950 
003 == clients == 0.103 train loss 0.149 | test loss 0.233 | train acc 0.945 | test acc 0.921    == global model ==  train loss 0.069 | test loss 0.089 | train acc 0.975 | test acc 0.967 
004 == clients == 0.081 train loss 0.085 | test loss 0.144 | train acc 0.971 | test acc 0.947    == global model ==  train loss 0.071 | test loss 0.078 | train acc 0.977 | test acc 0.967 
005 == clients == 0.069 train loss 0.080 | test loss 0.150 | train acc 0.973 | test acc 0.948    == global model ==  train loss 0.047 | test loss 0.065 | train acc 0.986 | test acc 0.974 
006 == clients == 0.061 train loss 0.064 | test loss 0.127 | train acc 0.980 | test acc 0.957    == global model ==  train loss 0.046 | test loss 0.064 | train acc 0.985 | test acc 0.976 
007 == clients == 0.055 train loss 0.058 | test loss 0.124 | train acc 0.980 | test acc 0.959    == global model ==  train loss 0.035 | test loss 0.058 | train acc 0.987 | test acc 0.979 
008 == clients == 0.052 train loss 0.047 | test loss 0.099 | train acc 0.984 | test acc 0.966    == global model ==  train loss 0.035 | test loss 0.050 | train acc 0.988 | test acc 0.979 
009 == clients == 0.048 train loss 0.049 | test loss 0.106 | train acc 0.982 | test acc 0.966    == global model ==  train loss 0.041 | test loss 0.049 | train acc 0.986 | test acc 0.983 
010 == clients == 0.043 train loss 0.039 | test loss 0.092 | train acc 0.986 | test acc 0.968    == global model ==  train loss 0.037 | test loss 0.049 | train acc 0.987 | test acc 0.981 
011 == clients == 0.042 train loss 0.051 | test loss 0.111 | train acc 0.981 | test acc 0.964    == global model ==  train loss 0.028 | test loss 0.048 | train acc 0.991 | test acc 0.983 
012 == clients == 0.039 train loss 0.037 | test loss 0.083 | train acc 0.986 | test acc 0.974    == global model ==  train loss 0.030 | test loss 0.050 | train acc 0.989 | test acc 0.984 
013 == clients == 0.038 train loss 0.032 | test loss 0.081 | train acc 0.988 | test acc 0.975    == global model ==  train loss 0.029 | test loss 0.045 | train acc 0.990 | test acc 0.986 
014 == clients == 0.036 train loss 0.030 | test loss 0.079 | train acc 0.989 | test acc 0.974    == global model ==  train loss 0.029 | test loss 0.048 | train acc 0.991 | test acc 0.983 
015 == clients == 0.035 train loss 0.031 | test loss 0.071 | train acc 0.989 | test acc 0.977    == global model ==  train loss 0.032 | test loss 0.040 | train acc 0.989 | test acc 0.986 
016 == clients == 0.033 train loss 0.024 | test loss 0.079 | train acc 0.991 | test acc 0.975    == global model ==  train loss 0.030 | test loss 0.040 | train acc 0.990 | test acc 0.986 
017 == clients == 0.031 train loss 0.028 | test loss 0.081 | train acc 0.990 | test acc 0.975    == global model ==  train loss 0.022 | test loss 0.038 | train acc 0.993 | test acc 0.986 
018 == clients == 0.030 train loss 0.024 | test loss 0.070 | train acc 0.992 | test acc 0.977    == global model ==  train loss 0.027 | test loss 0.036 | train acc 0.991 | test acc 0.993 
019 == clients == 0.029 train loss 0.018 | test loss 0.080 | train acc 0.994 | test acc 0.976    == global model ==  train loss 0.024 | test loss 0.045 | train acc 0.991 | test acc 0.984 
020 == clients == 0.028 train loss 0.027 | test loss 0.075 | train acc 0.990 | test acc 0.974    == global model ==  train loss 0.022 | test loss 0.040 | train acc 0.992 | test acc 0.988 
021 == clients == 0.028 train loss 0.021 | test loss 0.078 | train acc 0.993 | test acc 0.976    == global model ==  train loss 0.022 | test loss 0.044 | train acc 0.992 | test acc 0.986 
022 == clients == 0.026 train loss 0.023 | test loss 0.074 | train acc 0.992 | test acc 0.977    == global model ==  train loss 0.024 | test loss 0.043 | train acc 0.992 | test acc 0.986 
023 == clients == 0.024 train loss 0.021 | test loss 0.080 | train acc 0.993 | test acc 0.977    == global model ==  train loss 0.021 | test loss 0.044 | train acc 0.993 | test acc 0.988 
024 == clients == 0.023 train loss 0.022 | test loss 0.077 | train acc 0.992 | test acc 0.976    == global model ==  train loss 0.020 | test loss 0.045 | train acc 0.992 | test acc 0.988 
025 == clients == 0.023 train loss 0.015 | test loss 0.066 | train acc 0.995 | test acc 0.980    == global model ==  train loss 0.022 | test loss 0.039 | train acc 0.993 | test acc 0.990 
026 == clients == 0.025 train loss 0.017 | test loss 0.072 | train acc 0.994 | test acc 0.977    == global model ==  train loss 0.022 | test loss 0.039 | train acc 0.991 | test acc 0.988 
027 == clients == 0.023 train loss 0.018 | test loss 0.075 | train acc 0.993 | test acc 0.977    == global model ==  train loss 0.016 | test loss 0.039 | train acc 0.994 | test acc 0.990 
028 == clients == 0.022 train loss 0.022 | test loss 0.070 | train acc 0.992 | test acc 0.979    == global model ==  train loss 0.016 | test loss 0.040 | train acc 0.994 | test acc 0.988 
029 == clients == 0.021 train loss 0.019 | test loss 0.071 | train acc 0.993 | test acc 0.980    == global model ==  train loss 0.018 | test loss 0.044 | train acc 0.993 | test acc 0.986 
030 == clients == 0.022 train loss 0.019 | test loss 0.074 | train acc 0.993 | test acc 0.977    == global model ==  train loss 0.018 | test loss 0.039 | train acc 0.994 | test acc 0.990 
031 == clients == 0.022 train loss 0.015 | test loss 0.077 | train acc 0.996 | test acc 0.975    == global model ==  train loss 0.017 | test loss 0.040 | train acc 0.994 | test acc 0.988 
032 == clients == 0.020 train loss 0.016 | test loss 0.072 | train acc 0.994 | test acc 0.980    == global model ==  train loss 0.018 | test loss 0.042 | train acc 0.994 | test acc 0.991 
033 == clients == 0.021 train loss 0.017 | test loss 0.068 | train acc 0.993 | test acc 0.981    == global model ==  train loss 0.026 | test loss 0.040 | train acc 0.990 | test acc 0.988 
034 == clients == 0.019 train loss 0.016 | test loss 0.075 | train acc 0.994 | test acc 0.978    == global model ==  train loss 0.024 | test loss 0.041 | train acc 0.991 | test acc 0.990 
035 == clients == 0.018 train loss 0.016 | test loss 0.071 | train acc 0.995 | test acc 0.981    == global model ==  train loss 0.015 | test loss 0.040 | train acc 0.995 | test acc 0.990 
036 == clients == 0.018 train loss 0.012 | test loss 0.066 | train acc 0.996 | test acc 0.982    == global model ==  train loss 0.019 | test loss 0.039 | train acc 0.993 | test acc 0.993 
037 == clients == 0.017 train loss 0.011 | test loss 0.071 | train acc 0.996 | test acc 0.981    == global model ==  train loss 0.012 | test loss 0.043 | train acc 0.996 | test acc 0.990 
038 == clients == 0.018 train loss 0.014 | test loss 0.069 | train acc 0.996 | test acc 0.981    == global model ==  train loss 0.017 | test loss 0.037 | train acc 0.993 | test acc 0.990 
039 == clients == 0.017 train loss 0.014 | test loss 0.072 | train acc 0.995 | test acc 0.980    == global model ==  train loss 0.014 | test loss 0.040 | train acc 0.996 | test acc 0.991 
040 == clients == 0.018 train loss 0.014 | test loss 0.067 | train acc 0.995 | test acc 0.981    == global model ==  train loss 0.022 | test loss 0.037 | train acc 0.992 | test acc 0.988 
041 == clients == 0.017 train loss 0.013 | test loss 0.071 | train acc 0.995 | test acc 0.980    == global model ==  train loss 0.011 | test loss 0.041 | train acc 0.995 | test acc 0.988 
042 == clients == 0.016 train loss 0.010 | test loss 0.069 | train acc 0.997 | test acc 0.981    == global model ==  train loss 0.014 | test loss 0.044 | train acc 0.994 | test acc 0.988 
043 == clients == 0.017 train loss 0.011 | test loss 0.069 | train acc 0.995 | test acc 0.980    == global model ==  train loss 0.016 | test loss 0.040 | train acc 0.994 | test acc 0.990 
044 == clients == 0.015 train loss 0.010 | test loss 0.071 | train acc 0.996 | test acc 0.980    == global model ==  train loss 0.014 | test loss 0.043 | train acc 0.994 | test acc 0.990 
045 == clients == 0.015 train loss 0.012 | test loss 0.070 | train acc 0.996 | test acc 0.981    == global model ==  train loss 0.013 | test loss 0.038 | train acc 0.995 | test acc 0.990 
046 == clients == 0.015 train loss 0.010 | test loss 0.066 | train acc 0.997 | test acc 0.981    == global model ==  train loss 0.010 | test loss 0.038 | train acc 0.997 | test acc 0.991 
047 == clients == 0.015 train loss 0.013 | test loss 0.073 | train acc 0.997 | test acc 0.979    == global model ==  train loss 0.013 | test loss 0.038 | train acc 0.995 | test acc 0.991 
048 == clients == 0.015 train loss 0.012 | test loss 0.071 | train acc 0.995 | test acc 0.982    == global model ==  train loss 0.012 | test loss 0.043 | train acc 0.996 | test acc 0.990 
049 == clients == 0.015 train loss 0.013 | test loss 0.081 | train acc 0.996 | test acc 0.976    == global model ==  train loss 0.012 | test loss 0.045 | train acc 0.995 | test acc 0.990 
050 == clients == 0.015 train loss 0.014 | test loss 0.070 | train acc 0.995 | test acc 0.982    == global model ==  train loss 0.013 | test loss 0.042 | train acc 0.996 | test acc 0.990 
global model -- val_loss=0.045 -- val_acc=0.987 -- test_loss=0.029 -- test_acc=0.993
051 == clients == 0.015 train loss 0.015 | test loss 0.072 | train acc 0.994 | test acc 0.978    == global model ==  train loss 0.018 | test loss 0.041 | train acc 0.995 | test acc 0.990 
052 == clients == 0.014 train loss 0.014 | test loss 0.068 | train acc 0.994 | test acc 0.979    == global model ==  train loss 0.010 | test loss 0.039 | train acc 0.996 | test acc 0.991 
053 == clients == 0.013 train loss 0.009 | test loss 0.064 | train acc 0.997 | test acc 0.982    == global model ==  train loss 0.015 | test loss 0.040 | train acc 0.993 | test acc 0.991 
054 == clients == 0.013 train loss 0.010 | test loss 0.065 | train acc 0.996 | test acc 0.981    == global model ==  train loss 0.014 | test loss 0.037 | train acc 0.995 | test acc 0.990 
055 == clients == 0.013 train loss 0.009 | test loss 0.072 | train acc 0.996 | test acc 0.980    == global model ==  train loss 0.012 | test loss 0.040 | train acc 0.994 | test acc 0.988 
056 == clients == 0.013 train loss 0.010 | test loss 0.062 | train acc 0.997 | test acc 0.981    == global model ==  train loss 0.011 | test loss 0.035 | train acc 0.997 | test acc 0.990 
057 == clients == 0.013 train loss 0.009 | test loss 0.066 | train acc 0.997 | test acc 0.981    == global model ==  train loss 0.011 | test loss 0.042 | train acc 0.996 | test acc 0.988 
058 == clients == 0.012 train loss 0.007 | test loss 0.065 | train acc 0.998 | test acc 0.982    == global model ==  train loss 0.014 | test loss 0.041 | train acc 0.995 | test acc 0.988 
059 == clients == 0.011 train loss 0.010 | test loss 0.067 | train acc 0.996 | test acc 0.982    == global model ==  train loss 0.011 | test loss 0.042 | train acc 0.995 | test acc 0.988 
060 == clients == 0.013 train loss 0.009 | test loss 0.071 | train acc 0.997 | test acc 0.979    == global model ==  train loss 0.010 | test loss 0.044 | train acc 0.997 | test acc 0.990 
061 == clients == 0.012 train loss 0.009 | test loss 0.067 | train acc 0.998 | test acc 0.981    == global model ==  train loss 0.009 | test loss 0.045 | train acc 0.996 | test acc 0.988 
062 == clients == 0.013 train loss 0.009 | test loss 0.073 | train acc 0.997 | test acc 0.981    == global model ==  train loss 0.008 | test loss 0.046 | train acc 0.997 | test acc 0.990 
063 == clients == 0.012 train loss 0.010 | test loss 0.071 | train acc 0.997 | test acc 0.980    == global model ==  train loss 0.009 | test loss 0.046 | train acc 0.995 | test acc 0.988 
064 == clients == 0.011 train loss 0.010 | test loss 0.064 | train acc 0.995 | test acc 0.982    == global model ==  train loss 0.008 | test loss 0.045 | train acc 0.996 | test acc 0.988 
065 == clients == 0.011 train loss 0.006 | test loss 0.071 | train acc 0.998 | test acc 0.981    == global model ==  train loss 0.009 | test loss 0.045 | train acc 0.996 | test acc 0.990 
066 == clients == 0.011 train loss 0.008 | test loss 0.061 | train acc 0.997 | test acc 0.982    == global model ==  train loss 0.011 | test loss 0.037 | train acc 0.995 | test acc 0.991 
067 == clients == 0.011 train loss 0.008 | test loss 0.071 | train acc 0.998 | test acc 0.982    == global model ==  train loss 0.011 | test loss 0.042 | train acc 0.995 | test acc 0.991 
068 == clients == 0.011 train loss 0.007 | test loss 0.070 | train acc 0.998 | test acc 0.981    == global model ==  train loss 0.009 | test loss 0.043 | train acc 0.997 | test acc 0.990 
069 == clients == 0.011 train loss 0.007 | test loss 0.068 | train acc 0.998 | test acc 0.983    == global model ==  train loss 0.008 | test loss 0.046 | train acc 0.997 | test acc 0.990 
070 == clients == 0.009 train loss 0.006 | test loss 0.069 | train acc 0.997 | test acc 0.983    == global model ==  train loss 0.009 | test loss 0.047 | train acc 0.997 | test acc 0.990 
071 == clients == 0.011 train loss 0.005 | test loss 0.070 | train acc 0.998 | test acc 0.983    == global model ==  train loss 0.009 | test loss 0.043 | train acc 0.997 | test acc 0.991 
072 == clients == 0.011 train loss 0.006 | test loss 0.062 | train acc 0.998 | test acc 0.983    == global model ==  train loss 0.009 | test loss 0.042 | train acc 0.997 | test acc 0.990 
073 == clients == 0.011 train loss 0.007 | test loss 0.069 | train acc 0.998 | test acc 0.980    == global model ==  train loss 0.009 | test loss 0.042 | train acc 0.996 | test acc 0.990 
074 == clients == 0.010 train loss 0.008 | test loss 0.066 | train acc 0.997 | test acc 0.982    == global model ==  train loss 0.011 | test loss 0.045 | train acc 0.995 | test acc 0.988 
075 == clients == 0.009 train loss 0.009 | test loss 0.065 | train acc 0.997 | test acc 0.982    == global model ==  train loss 0.010 | test loss 0.040 | train acc 0.996 | test acc 0.990 
076 == clients == 0.009 train loss 0.005 | test loss 0.078 | train acc 0.998 | test acc 0.978    == global model ==  train loss 0.012 | test loss 0.051 | train acc 0.995 | test acc 0.990 
077 == clients == 0.010 train loss 0.006 | test loss 0.067 | train acc 0.999 | test acc 0.983    == global model ==  train loss 0.010 | test loss 0.044 | train acc 0.997 | test acc 0.991 
078 == clients == 0.010 train loss 0.006 | test loss 0.081 | train acc 0.998 | test acc 0.980    == global model ==  train loss 0.008 | test loss 0.051 | train acc 0.998 | test acc 0.990 
079 == clients == 0.009 train loss 0.005 | test loss 0.065 | train acc 0.999 | test acc 0.982    == global model ==  train loss 0.010 | test loss 0.042 | train acc 0.996 | test acc 0.990 
080 == clients == 0.009 train loss 0.005 | test loss 0.070 | train acc 0.998 | test acc 0.982    == global model ==  train loss 0.010 | test loss 0.043 | train acc 0.996 | test acc 0.990 
081 == clients == 0.009 train loss 0.008 | test loss 0.063 | train acc 0.997 | test acc 0.983    == global model ==  train loss 0.006 | test loss 0.042 | train acc 0.997 | test acc 0.991 
082 == clients == 0.009 train loss 0.006 | test loss 0.071 | train acc 0.998 | test acc 0.982    == global model ==  train loss 0.008 | test loss 0.046 | train acc 0.996 | test acc 0.990 
083 == clients == 0.009 train loss 0.006 | test loss 0.080 | train acc 0.998 | test acc 0.981    == global model ==  train loss 0.012 | test loss 0.050 | train acc 0.997 | test acc 0.990 
084 == clients == 0.008 train loss 0.004 | test loss 0.076 | train acc 0.998 | test acc 0.980    == global model ==  train loss 0.010 | test loss 0.051 | train acc 0.995 | test acc 0.986 
085 == clients == 0.008 train loss 0.006 | test loss 0.073 | train acc 0.998 | test acc 0.982    == global model ==  train loss 0.008 | test loss 0.047 | train acc 0.997 | test acc 0.990 
086 == clients == 0.009 train loss 0.006 | test loss 0.075 | train acc 0.999 | test acc 0.979    == global model ==  train loss 0.008 | test loss 0.045 | train acc 0.997 | test acc 0.990 
087 == clients == 0.010 train loss 0.007 | test loss 0.075 | train acc 0.998 | test acc 0.980    == global model ==  train loss 0.008 | test loss 0.047 | train acc 0.997 | test acc 0.988 
088 == clients == 0.008 train loss 0.005 | test loss 0.070 | train acc 0.998 | test acc 0.982    == global model ==  train loss 0.007 | test loss 0.044 | train acc 0.997 | test acc 0.988 
089 == clients == 0.009 train loss 0.007 | test loss 0.070 | train acc 0.997 | test acc 0.982    == global model ==  train loss 0.010 | test loss 0.049 | train acc 0.997 | test acc 0.990 
090 == clients == 0.008 train loss 0.004 | test loss 0.066 | train acc 0.998 | test acc 0.983    == global model ==  train loss 0.011 | test loss 0.044 | train acc 0.996 | test acc 0.988 
091 == clients == 0.008 train loss 0.005 | test loss 0.068 | train acc 0.998 | test acc 0.982    == global model ==  train loss 0.006 | test loss 0.045 | train acc 0.998 | test acc 0.990 
092 == clients == 0.008 train loss 0.005 | test loss 0.068 | train acc 0.999 | test acc 0.982    == global model ==  train loss 0.009 | test loss 0.045 | train acc 0.997 | test acc 0.990 
093 == clients == 0.009 train loss 0.005 | test loss 0.068 | train acc 0.998 | test acc 0.983    == global model ==  train loss 0.005 | test loss 0.040 | train acc 0.999 | test acc 0.990 
094 == clients == 0.008 train loss 0.005 | test loss 0.072 | train acc 0.999 | test acc 0.982    == global model ==  train loss 0.009 | test loss 0.047 | train acc 0.997 | test acc 0.988 
095 == clients == 0.008 train loss 0.004 | test loss 0.072 | train acc 0.999 | test acc 0.982    == global model ==  train loss 0.006 | test loss 0.044 | train acc 0.998 | test acc 0.990 
096 == clients == 0.008 train loss 0.006 | test loss 0.063 | train acc 0.998 | test acc 0.983    == global model ==  train loss 0.009 | test loss 0.040 | train acc 0.997 | test acc 0.990 
097 == clients == 0.008 train loss 0.006 | test loss 0.070 | train acc 0.998 | test acc 0.981    == global model ==  train loss 0.007 | test loss 0.046 | train acc 0.997 | test acc 0.988 
098 == clients == 0.007 train loss 0.005 | test loss 0.074 | train acc 0.999 | test acc 0.981    == global model ==  train loss 0.008 | test loss 0.045 | train acc 0.997 | test acc 0.991 
099 == clients == 0.008 train loss 0.005 | test loss 0.069 | train acc 0.999 | test acc 0.982    == global model ==  train loss 0.007 | test loss 0.046 | train acc 0.997 | test acc 0.991 
100 == clients == 0.009 train loss 0.003 | test loss 0.072 | train acc 0.999 | test acc 0.981    == global model ==  train loss 0.007 | test loss 0.045 | train acc 0.997 | test acc 0.988 
global model -- val_loss=0.046 -- val_acc=0.988 -- test_loss=0.031 -- test_acc=0.993
===================== Start Stage-2 =====================
checkpoint=PosixPath('../experiments/mnist_tct_small_resnet14_iid_partition/checkpoints/mnist_tct_small_resnet14_iid_partition_stage1_model_100.pth')
stage2 model -- client_train_loss=0.008 -- client_train_acc=0.997 -- test_loss=0.031 -- test_acc=0.993
loaded eNTK model
Compute eNTK representations
normalization
round_idx=1: train_acc=0.996 test_acc=0.992    train_max_score=0.982 test_max_score=0.994   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=2: train_acc=0.997 test_acc=0.993    train_max_score=0.988 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=3: train_acc=0.998 test_acc=0.993    train_max_score=0.990 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=4: train_acc=0.998 test_acc=0.993    train_max_score=0.992 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=5: train_acc=0.998 test_acc=0.993    train_max_score=0.993 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=6: train_acc=0.998 test_acc=0.993    train_max_score=0.993 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=7: train_acc=0.998 test_acc=0.994    train_max_score=0.994 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=8: train_acc=0.998 test_acc=0.994    train_max_score=0.994 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=9: train_acc=0.998 test_acc=0.994    train_max_score=0.994 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=10: train_acc=0.998 test_acc=0.994    train_max_score=0.995 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=11: train_acc=0.999 test_acc=0.994    train_max_score=0.995 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=12: train_acc=0.999 test_acc=0.994    train_max_score=0.995 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=13: train_acc=0.999 test_acc=0.994    train_max_score=0.995 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=14: train_acc=0.999 test_acc=0.994    train_max_score=0.996 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=15: train_acc=0.999 test_acc=0.994    train_max_score=0.996 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=16: train_acc=0.999 test_acc=0.994    train_max_score=0.996 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=17: train_acc=0.999 test_acc=0.994    train_max_score=0.996 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=18: train_acc=0.999 test_acc=0.994    train_max_score=0.996 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=19: train_acc=0.999 test_acc=0.994    train_max_score=0.996 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=20: train_acc=0.999 test_acc=0.994    train_max_score=0.996 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=21: train_acc=0.999 test_acc=0.994    train_max_score=0.996 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=22: train_acc=0.999 test_acc=0.994    train_max_score=0.996 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=23: train_acc=0.999 test_acc=0.994    train_max_score=0.996 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=24: train_acc=0.999 test_acc=0.994    train_max_score=0.997 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=25: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=26: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=27: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=28: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=29: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=30: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=31: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=32: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.996   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=33: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=34: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=35: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=36: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=37: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=38: train_acc=0.999 test_acc=0.995    train_max_score=0.997 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=39: train_acc=1.000 test_acc=0.995    train_max_score=0.997 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=40: train_acc=1.000 test_acc=0.995    train_max_score=0.997 test_max_score=0.995   q_10=0.001 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=41: train_acc=1.000 test_acc=0.995    train_max_score=0.997 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=42: train_acc=1.000 test_acc=0.995    train_max_score=0.997 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=43: train_acc=1.000 test_acc=0.995    train_max_score=0.997 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=44: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=45: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=46: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=47: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=48: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=49: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=50: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=51: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=52: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=53: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=54: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=55: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=56: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=57: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=58: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=59: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=60: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=61: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=62: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=63: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=64: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=65: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=66: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=67: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=68: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=69: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=70: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=71: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=72: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=73: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=74: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=75: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=76: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=77: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=78: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=79: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=80: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=81: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=82: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=83: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=84: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=85: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=86: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=87: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=88: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=89: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=90: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=91: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=92: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=93: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=94: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=95: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=96: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=97: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=98: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=99: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
round_idx=100: train_acc=1.000 test_acc=0.995    train_max_score=0.998 test_max_score=0.995   q_10=0.002 size_10=1.0 q_20=0.000 size_20=1.0 q_30=0.000 size_30=1.0
 Finished TCT Stage-2 
==========total runtime 22784===========
