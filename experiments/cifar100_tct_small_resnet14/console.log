========== CIFAR100_TCT_SMALL_RESNET14 ===========
client 0 train samples 2500
client 1 train samples 2500
client 2 train samples 2500
client 3 train samples 2500
client 4 train samples 2500
client 5 train samples 2500
client 6 train samples 2500
client 7 train samples 2500
client 8 train samples 2500
client 9 train samples 2500
client 10 train samples 2500
client 11 train samples 2500
client 12 train samples 2500
client 13 train samples 2500
client 14 train samples 2500
client 15 train samples 2500
client 16 train samples 2500
client 17 train samples 2500
client 18 train samples 2500
client 19 train samples 2500
val samples--------- 1000
test samples-------- 9000
===================== Start Stage-1 =====================
len(client_models)=20
len(train_loaders)=20
opt[0]=SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.01
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
001 == clients == 1.102 train loss 0.998 | test loss 11.898 | train acc 0.559 | test acc 0.026    == global model ==  train loss 4.383 | test loss 4.372 | train acc 0.016 | test acc 0.012 
002 == clients == 1.071 train loss 0.987 | test loss 11.527 | train acc 0.560 | test acc 0.027    == global model ==  train loss 4.264 | test loss 4.253 | train acc 0.015 | test acc 0.016 
003 == clients == 1.023 train loss 0.943 | test loss 11.529 | train acc 0.595 | test acc 0.028    == global model ==  train loss 4.192 | test loss 4.197 | train acc 0.015 | test acc 0.017 
004 == clients == 0.991 train loss 0.962 | test loss 11.916 | train acc 0.585 | test acc 0.026    == global model ==  train loss 4.150 | test loss 4.161 | train acc 0.016 | test acc 0.016 
005 == clients == 0.965 train loss 0.890 | test loss 11.507 | train acc 0.613 | test acc 0.028    == global model ==  train loss 4.129 | test loss 4.138 | train acc 0.013 | test acc 0.014 
006 == clients == 0.937 train loss 0.869 | test loss 11.672 | train acc 0.624 | test acc 0.030    == global model ==  train loss 4.096 | test loss 4.097 | train acc 0.022 | test acc 0.030 
007 == clients == 0.910 train loss 0.848 | test loss 11.683 | train acc 0.629 | test acc 0.030    == global model ==  train loss 4.074 | test loss 4.084 | train acc 0.026 | test acc 0.028 
008 == clients == 0.878 train loss 0.820 | test loss 11.740 | train acc 0.644 | test acc 0.029    == global model ==  train loss 4.047 | test loss 4.057 | train acc 0.030 | test acc 0.033 
009 == clients == 0.867 train loss 0.789 | test loss 11.513 | train acc 0.657 | test acc 0.031    == global model ==  train loss 4.034 | test loss 4.036 | train acc 0.038 | test acc 0.040 
010 == clients == 0.836 train loss 0.800 | test loss 11.480 | train acc 0.659 | test acc 0.030    == global model ==  train loss 4.015 | test loss 4.024 | train acc 0.042 | test acc 0.040 
011 == clients == 0.823 train loss 0.779 | test loss 11.876 | train acc 0.666 | test acc 0.031    == global model ==  train loss 4.009 | test loss 4.007 | train acc 0.043 | test acc 0.043 
012 == clients == 0.813 train loss 0.775 | test loss 11.769 | train acc 0.668 | test acc 0.031    == global model ==  train loss 3.988 | test loss 3.986 | train acc 0.048 | test acc 0.038 
013 == clients == 0.793 train loss 0.754 | test loss 11.924 | train acc 0.677 | test acc 0.032    == global model ==  train loss 3.966 | test loss 3.964 | train acc 0.051 | test acc 0.043 
014 == clients == 0.766 train loss 0.718 | test loss 11.882 | train acc 0.694 | test acc 0.033    == global model ==  train loss 3.945 | test loss 3.952 | train acc 0.056 | test acc 0.047 
015 == clients == 0.770 train loss 0.698 | test loss 11.776 | train acc 0.698 | test acc 0.033    == global model ==  train loss 3.936 | test loss 3.939 | train acc 0.055 | test acc 0.049 
016 == clients == 0.748 train loss 0.710 | test loss 11.676 | train acc 0.697 | test acc 0.033    == global model ==  train loss 3.919 | test loss 3.925 | train acc 0.063 | test acc 0.049 
017 == clients == 0.732 train loss 0.676 | test loss 11.758 | train acc 0.711 | test acc 0.034    == global model ==  train loss 3.911 | test loss 3.903 | train acc 0.065 | test acc 0.054 
018 == clients == 0.732 train loss 0.727 | test loss 12.032 | train acc 0.693 | test acc 0.032    == global model ==  train loss 3.889 | test loss 3.880 | train acc 0.069 | test acc 0.059 
019 == clients == 0.723 train loss 0.682 | test loss 11.998 | train acc 0.708 | test acc 0.033    == global model ==  train loss 3.877 | test loss 3.869 | train acc 0.070 | test acc 0.066 
020 == clients == 0.713 train loss 0.646 | test loss 12.202 | train acc 0.726 | test acc 0.034    == global model ==  train loss 3.858 | test loss 3.860 | train acc 0.074 | test acc 0.057 
021 == clients == 0.699 train loss 0.646 | test loss 12.008 | train acc 0.732 | test acc 0.033    == global model ==  train loss 3.850 | test loss 3.843 | train acc 0.075 | test acc 0.052 
022 == clients == 0.677 train loss 0.626 | test loss 12.134 | train acc 0.731 | test acc 0.035    == global model ==  train loss 3.843 | test loss 3.830 | train acc 0.079 | test acc 0.066 
023 == clients == 0.671 train loss 0.581 | test loss 12.171 | train acc 0.751 | test acc 0.034    == global model ==  train loss 3.831 | test loss 3.820 | train acc 0.081 | test acc 0.071 
024 == clients == 0.675 train loss 0.605 | test loss 12.101 | train acc 0.745 | test acc 0.034    == global model ==  train loss 3.812 | test loss 3.803 | train acc 0.087 | test acc 0.085 
025 == clients == 0.662 train loss 0.609 | test loss 12.240 | train acc 0.743 | test acc 0.034    == global model ==  train loss 3.812 | test loss 3.798 | train acc 0.085 | test acc 0.076 
026 == clients == 0.659 train loss 0.617 | test loss 11.983 | train acc 0.739 | test acc 0.034    == global model ==  train loss 3.808 | test loss 3.792 | train acc 0.087 | test acc 0.078 
027 == clients == 0.644 train loss 0.592 | test loss 12.087 | train acc 0.747 | test acc 0.034    == global model ==  train loss 3.780 | test loss 3.782 | train acc 0.091 | test acc 0.090 
028 == clients == 0.645 train loss 0.592 | test loss 12.304 | train acc 0.749 | test acc 0.034    == global model ==  train loss 3.778 | test loss 3.772 | train acc 0.089 | test acc 0.104 
029 == clients == 0.642 train loss 0.595 | test loss 12.356 | train acc 0.751 | test acc 0.035    == global model ==  train loss 3.769 | test loss 3.766 | train acc 0.096 | test acc 0.095 
030 == clients == 0.631 train loss 0.565 | test loss 12.379 | train acc 0.762 | test acc 0.034    == global model ==  train loss 3.745 | test loss 3.756 | train acc 0.098 | test acc 0.089 
031 == clients == 0.626 train loss 0.567 | test loss 12.295 | train acc 0.762 | test acc 0.035    == global model ==  train loss 3.744 | test loss 3.753 | train acc 0.103 | test acc 0.090 
032 == clients == 0.618 train loss 0.543 | test loss 12.180 | train acc 0.775 | test acc 0.035    == global model ==  train loss 3.737 | test loss 3.733 | train acc 0.099 | test acc 0.094 
033 == clients == 0.613 train loss 0.591 | test loss 12.346 | train acc 0.755 | test acc 0.034    == global model ==  train loss 3.722 | test loss 3.733 | train acc 0.104 | test acc 0.092 
034 == clients == 0.607 train loss 0.538 | test loss 12.213 | train acc 0.777 | test acc 0.035    == global model ==  train loss 3.718 | test loss 3.732 | train acc 0.105 | test acc 0.097 
035 == clients == 0.598 train loss 0.555 | test loss 12.426 | train acc 0.768 | test acc 0.035    == global model ==  train loss 3.709 | test loss 3.717 | train acc 0.108 | test acc 0.101 
036 == clients == 0.597 train loss 0.529 | test loss 12.336 | train acc 0.779 | test acc 0.034    == global model ==  train loss 3.698 | test loss 3.714 | train acc 0.103 | test acc 0.092 
037 == clients == 0.595 train loss 0.547 | test loss 12.248 | train acc 0.773 | test acc 0.035    == global model ==  train loss 3.694 | test loss 3.711 | train acc 0.108 | test acc 0.094 
038 == clients == 0.587 train loss 0.564 | test loss 12.307 | train acc 0.764 | test acc 0.034    == global model ==  train loss 3.682 | test loss 3.708 | train acc 0.110 | test acc 0.108 
039 == clients == 0.576 train loss 0.508 | test loss 12.262 | train acc 0.784 | test acc 0.035    == global model ==  train loss 3.670 | test loss 3.692 | train acc 0.110 | test acc 0.104 
040 == clients == 0.570 train loss 0.517 | test loss 12.405 | train acc 0.784 | test acc 0.035    == global model ==  train loss 3.664 | test loss 3.690 | train acc 0.111 | test acc 0.106 
041 == clients == 0.563 train loss 0.511 | test loss 12.300 | train acc 0.785 | test acc 0.036    == global model ==  train loss 3.658 | test loss 3.681 | train acc 0.117 | test acc 0.111 
042 == clients == 0.560 train loss 0.519 | test loss 12.169 | train acc 0.784 | test acc 0.035    == global model ==  train loss 3.649 | test loss 3.677 | train acc 0.119 | test acc 0.115 
043 == clients == 0.557 train loss 0.503 | test loss 12.261 | train acc 0.792 | test acc 0.036    == global model ==  train loss 3.648 | test loss 3.670 | train acc 0.120 | test acc 0.116 
044 == clients == 0.560 train loss 0.506 | test loss 12.348 | train acc 0.792 | test acc 0.036    == global model ==  train loss 3.634 | test loss 3.655 | train acc 0.120 | test acc 0.123 
045 == clients == 0.550 train loss 0.473 | test loss 12.074 | train acc 0.803 | test acc 0.036    == global model ==  train loss 3.645 | test loss 3.662 | train acc 0.122 | test acc 0.120 
046 == clients == 0.555 train loss 0.481 | test loss 12.147 | train acc 0.795 | test acc 0.035    == global model ==  train loss 3.628 | test loss 3.660 | train acc 0.128 | test acc 0.118 
047 == clients == 0.539 train loss 0.458 | test loss 12.178 | train acc 0.804 | test acc 0.036    == global model ==  train loss 3.607 | test loss 3.638 | train acc 0.126 | test acc 0.123 
048 == clients == 0.543 train loss 0.464 | test loss 12.233 | train acc 0.804 | test acc 0.036    == global model ==  train loss 3.612 | test loss 3.650 | train acc 0.126 | test acc 0.122 
049 == clients == 0.533 train loss 0.472 | test loss 12.147 | train acc 0.800 | test acc 0.036    == global model ==  train loss 3.605 | test loss 3.625 | train acc 0.127 | test acc 0.128 
050 == clients == 0.532 train loss 0.495 | test loss 12.392 | train acc 0.790 | test acc 0.036    == global model ==  train loss 3.584 | test loss 3.617 | train acc 0.131 | test acc 0.123 
global model -- val_loss=3.865 -- val_acc=0.133 -- test_loss=3.932 -- test_acc=0.132
051 == clients == 0.528 train loss 0.478 | test loss 12.374 | train acc 0.800 | test acc 0.037    == global model ==  train loss 3.584 | test loss 3.608 | train acc 0.128 | test acc 0.130 
052 == clients == 0.517 train loss 0.480 | test loss 12.306 | train acc 0.798 | test acc 0.035    == global model ==  train loss 3.589 | test loss 3.611 | train acc 0.133 | test acc 0.141 
053 == clients == 0.514 train loss 0.466 | test loss 12.378 | train acc 0.805 | test acc 0.035    == global model ==  train loss 3.566 | test loss 3.601 | train acc 0.130 | test acc 0.127 
054 == clients == 0.525 train loss 0.472 | test loss 12.261 | train acc 0.798 | test acc 0.036    == global model ==  train loss 3.564 | test loss 3.601 | train acc 0.137 | test acc 0.127 
055 == clients == 0.498 train loss 0.428 | test loss 12.192 | train acc 0.822 | test acc 0.036    == global model ==  train loss 3.553 | test loss 3.591 | train acc 0.135 | test acc 0.139 
056 == clients == 0.508 train loss 0.424 | test loss 12.344 | train acc 0.821 | test acc 0.037    == global model ==  train loss 3.554 | test loss 3.586 | train acc 0.136 | test acc 0.137 
057 == clients == 0.517 train loss 0.441 | test loss 12.019 | train acc 0.813 | test acc 0.035    == global model ==  train loss 3.544 | test loss 3.587 | train acc 0.139 | test acc 0.151 
058 == clients == 0.499 train loss 0.445 | test loss 12.559 | train acc 0.810 | test acc 0.036    == global model ==  train loss 3.518 | test loss 3.577 | train acc 0.145 | test acc 0.137 
059 == clients == 0.509 train loss 0.473 | test loss 12.193 | train acc 0.804 | test acc 0.036    == global model ==  train loss 3.528 | test loss 3.568 | train acc 0.139 | test acc 0.137 
060 == clients == 0.487 train loss 0.431 | test loss 12.342 | train acc 0.820 | test acc 0.036    == global model ==  train loss 3.522 | test loss 3.562 | train acc 0.147 | test acc 0.134 
061 == clients == 0.487 train loss 0.415 | test loss 12.343 | train acc 0.827 | test acc 0.036    == global model ==  train loss 3.515 | test loss 3.553 | train acc 0.145 | test acc 0.142 
062 == clients == 0.491 train loss 0.442 | test loss 12.459 | train acc 0.816 | test acc 0.035    == global model ==  train loss 3.496 | test loss 3.547 | train acc 0.148 | test acc 0.148 
063 == clients == 0.486 train loss 0.430 | test loss 12.507 | train acc 0.819 | test acc 0.037    == global model ==  train loss 3.499 | test loss 3.547 | train acc 0.144 | test acc 0.148 
064 == clients == 0.475 train loss 0.445 | test loss 12.352 | train acc 0.817 | test acc 0.036    == global model ==  train loss 3.496 | test loss 3.543 | train acc 0.150 | test acc 0.151 
065 == clients == 0.485 train loss 0.391 | test loss 12.340 | train acc 0.837 | test acc 0.036    == global model ==  train loss 3.479 | test loss 3.529 | train acc 0.152 | test acc 0.141 
066 == clients == 0.477 train loss 0.393 | test loss 12.248 | train acc 0.838 | test acc 0.037    == global model ==  train loss 3.493 | test loss 3.529 | train acc 0.154 | test acc 0.151 
067 == clients == 0.478 train loss 0.383 | test loss 12.423 | train acc 0.837 | test acc 0.037    == global model ==  train loss 3.465 | test loss 3.530 | train acc 0.156 | test acc 0.142 
068 == clients == 0.484 train loss 0.410 | test loss 12.470 | train acc 0.835 | test acc 0.036    == global model ==  train loss 3.469 | test loss 3.526 | train acc 0.157 | test acc 0.161 
069 == clients == 0.471 train loss 0.414 | test loss 12.286 | train acc 0.828 | test acc 0.037    == global model ==  train loss 3.459 | test loss 3.510 | train acc 0.153 | test acc 0.142 
070 == clients == 0.463 train loss 0.404 | test loss 12.505 | train acc 0.835 | test acc 0.037    == global model ==  train loss 3.438 | test loss 3.512 | train acc 0.157 | test acc 0.155 
071 == clients == 0.453 train loss 0.389 | test loss 12.437 | train acc 0.835 | test acc 0.036    == global model ==  train loss 3.449 | test loss 3.518 | train acc 0.156 | test acc 0.156 
072 == clients == 0.458 train loss 0.389 | test loss 12.542 | train acc 0.847 | test acc 0.037    == global model ==  train loss 3.442 | test loss 3.499 | train acc 0.152 | test acc 0.156 
073 == clients == 0.463 train loss 0.396 | test loss 12.490 | train acc 0.837 | test acc 0.036    == global model ==  train loss 3.432 | test loss 3.506 | train acc 0.157 | test acc 0.149 
074 == clients == 0.447 train loss 0.402 | test loss 12.446 | train acc 0.834 | test acc 0.036    == global model ==  train loss 3.433 | test loss 3.500 | train acc 0.165 | test acc 0.144 
075 == clients == 0.461 train loss 0.358 | test loss 12.345 | train acc 0.850 | test acc 0.037    == global model ==  train loss 3.422 | test loss 3.493 | train acc 0.164 | test acc 0.149 
076 == clients == 0.443 train loss 0.371 | test loss 12.256 | train acc 0.845 | test acc 0.036    == global model ==  train loss 3.430 | test loss 3.492 | train acc 0.159 | test acc 0.149 
077 == clients == 0.446 train loss 0.369 | test loss 12.318 | train acc 0.849 | test acc 0.036    == global model ==  train loss 3.412 | test loss 3.476 | train acc 0.162 | test acc 0.153 
078 == clients == 0.442 train loss 0.370 | test loss 12.458 | train acc 0.843 | test acc 0.037    == global model ==  train loss 3.415 | test loss 3.472 | train acc 0.164 | test acc 0.148 
079 == clients == 0.426 train loss 0.386 | test loss 12.561 | train acc 0.843 | test acc 0.037    == global model ==  train loss 3.408 | test loss 3.464 | train acc 0.167 | test acc 0.153 
080 == clients == 0.444 train loss 0.356 | test loss 12.476 | train acc 0.849 | test acc 0.037    == global model ==  train loss 3.393 | test loss 3.469 | train acc 0.167 | test acc 0.151 
081 == clients == 0.436 train loss 0.356 | test loss 12.481 | train acc 0.852 | test acc 0.037    == global model ==  train loss 3.389 | test loss 3.455 | train acc 0.168 | test acc 0.156 
082 == clients == 0.448 train loss 0.359 | test loss 12.411 | train acc 0.851 | test acc 0.037    == global model ==  train loss 3.405 | test loss 3.456 | train acc 0.163 | test acc 0.161 
083 == clients == 0.420 train loss 0.402 | test loss 12.564 | train acc 0.835 | test acc 0.037    == global model ==  train loss 3.379 | test loss 3.450 | train acc 0.172 | test acc 0.170 
084 == clients == 0.435 train loss 0.335 | test loss 12.409 | train acc 0.864 | test acc 0.037    == global model ==  train loss 3.377 | test loss 3.441 | train acc 0.172 | test acc 0.163 
085 == clients == 0.438 train loss 0.375 | test loss 12.462 | train acc 0.846 | test acc 0.036    == global model ==  train loss 3.366 | test loss 3.426 | train acc 0.169 | test acc 0.165 
086 == clients == 0.419 train loss 0.347 | test loss 12.351 | train acc 0.856 | test acc 0.038    == global model ==  train loss 3.389 | test loss 3.442 | train acc 0.166 | test acc 0.160 
087 == clients == 0.417 train loss 0.326 | test loss 12.372 | train acc 0.866 | test acc 0.038    == global model ==  train loss 3.356 | test loss 3.422 | train acc 0.177 | test acc 0.167 
088 == clients == 0.422 train loss 0.360 | test loss 12.517 | train acc 0.851 | test acc 0.037    == global model ==  train loss 3.342 | test loss 3.432 | train acc 0.180 | test acc 0.158 
089 == clients == 0.418 train loss 0.348 | test loss 12.416 | train acc 0.856 | test acc 0.037    == global model ==  train loss 3.346 | test loss 3.417 | train acc 0.171 | test acc 0.155 
090 == clients == 0.415 train loss 0.346 | test loss 12.564 | train acc 0.857 | test acc 0.038    == global model ==  train loss 3.350 | test loss 3.426 | train acc 0.174 | test acc 0.155 
091 == clients == 0.414 train loss 0.334 | test loss 12.377 | train acc 0.862 | test acc 0.037    == global model ==  train loss 3.356 | test loss 3.415 | train acc 0.175 | test acc 0.161 
092 == clients == 0.430 train loss 0.335 | test loss 12.556 | train acc 0.863 | test acc 0.037    == global model ==  train loss 3.341 | test loss 3.412 | train acc 0.180 | test acc 0.155 
093 == clients == 0.404 train loss 0.342 | test loss 12.431 | train acc 0.857 | test acc 0.037    == global model ==  train loss 3.340 | test loss 3.413 | train acc 0.177 | test acc 0.172 
094 == clients == 0.408 train loss 0.355 | test loss 12.469 | train acc 0.852 | test acc 0.037    == global model ==  train loss 3.327 | test loss 3.404 | train acc 0.177 | test acc 0.165 
095 == clients == 0.397 train loss 0.340 | test loss 12.534 | train acc 0.862 | test acc 0.038    == global model ==  train loss 3.334 | test loss 3.405 | train acc 0.179 | test acc 0.161 
096 == clients == 0.399 train loss 0.315 | test loss 12.540 | train acc 0.869 | test acc 0.037    == global model ==  train loss 3.318 | test loss 3.391 | train acc 0.183 | test acc 0.160 
097 == clients == 0.414 train loss 0.329 | test loss 12.671 | train acc 0.865 | test acc 0.037    == global model ==  train loss 3.322 | test loss 3.402 | train acc 0.183 | test acc 0.155 
098 == clients == 0.408 train loss 0.323 | test loss 12.449 | train acc 0.867 | test acc 0.037    == global model ==  train loss 3.323 | test loss 3.396 | train acc 0.178 | test acc 0.163 
099 == clients == 0.406 train loss 0.336 | test loss 12.557 | train acc 0.861 | test acc 0.037    == global model ==  train loss 3.301 | test loss 3.393 | train acc 0.179 | test acc 0.168 
100 == clients == 0.398 train loss 0.348 | test loss 12.719 | train acc 0.854 | test acc 0.038    == global model ==  train loss 3.315 | test loss 3.401 | train acc 0.178 | test acc 0.167 
global model -- val_loss=3.622 -- val_acc=0.171 -- test_loss=3.694 -- test_acc=0.170
===================== Start Stage-2 =====================
checkpoint=PosixPath('experiments/cifar100_tct_small_resnet14/checkpoints/cifar100_tct_small_resnet14_stage1_model_100.pth')
stage2 model -- client_train_loss=3.509 -- client_train_acc=0.185 -- test_loss=3.694 -- test_acc=0.170
loaded eNTK model
Compute eNTK representations
normalization
round_idx=1: train_acc=0.483 test_acc=0.408    train_max_score=0.017 test_max_score=0.086   q_10=0.983 size_10=14.7 q_20=0.974 size_20=7.5 q_30=0.966 size_30=4.3
round_idx=2: train_acc=0.492 test_acc=0.420    train_max_score=0.032 test_max_score=0.339   q_10=0.987 size_10=12.3 q_20=0.968 size_20=6.2 q_30=0.938 size_30=3.3
round_idx=3: train_acc=0.503 test_acc=0.430    train_max_score=0.059 test_max_score=0.419   q_10=0.990 size_10=12.1 q_20=0.971 size_20=6.0 q_30=0.937 size_30=3.2
round_idx=4: train_acc=0.514 test_acc=0.439    train_max_score=0.097 test_max_score=0.430   q_10=0.991 size_10=12.3 q_20=0.970 size_20=5.7 q_30=0.938 size_30=3.2
round_idx=5: train_acc=0.525 test_acc=0.447    train_max_score=0.143 test_max_score=0.440   q_10=0.991 size_10=12.2 q_20=0.969 size_20=5.5 q_30=0.938 size_30=3.1
round_idx=6: train_acc=0.535 test_acc=0.454    train_max_score=0.190 test_max_score=0.449   q_10=0.991 size_10=12.3 q_20=0.968 size_20=5.2 q_30=0.937 size_30=3.0
round_idx=7: train_acc=0.546 test_acc=0.464    train_max_score=0.233 test_max_score=0.457   q_10=0.991 size_10=11.9 q_20=0.967 size_20=5.0 q_30=0.934 size_30=2.9
round_idx=8: train_acc=0.557 test_acc=0.470    train_max_score=0.270 test_max_score=0.464   q_10=0.990 size_10=11.3 q_20=0.966 size_20=4.8 q_30=0.933 size_30=2.8
round_idx=9: train_acc=0.566 test_acc=0.476    train_max_score=0.302 test_max_score=0.470   q_10=0.990 size_10=11.0 q_20=0.966 size_20=4.8 q_30=0.930 size_30=2.7
round_idx=10: train_acc=0.576 test_acc=0.481    train_max_score=0.329 test_max_score=0.476   q_10=0.989 size_10=10.6 q_20=0.965 size_20=4.6 q_30=0.929 size_30=2.7
round_idx=11: train_acc=0.586 test_acc=0.485    train_max_score=0.352 test_max_score=0.481   q_10=0.990 size_10=10.5 q_20=0.965 size_20=4.6 q_30=0.926 size_30=2.6
round_idx=12: train_acc=0.595 test_acc=0.491    train_max_score=0.372 test_max_score=0.485   q_10=0.989 size_10=10.0 q_20=0.965 size_20=4.5 q_30=0.925 size_30=2.5
round_idx=13: train_acc=0.604 test_acc=0.495    train_max_score=0.390 test_max_score=0.489   q_10=0.988 size_10=9.7 q_20=0.964 size_20=4.5 q_30=0.924 size_30=2.5
round_idx=14: train_acc=0.612 test_acc=0.499    train_max_score=0.405 test_max_score=0.493   q_10=0.988 size_10=9.3 q_20=0.965 size_20=4.5 q_30=0.921 size_30=2.4
round_idx=15: train_acc=0.620 test_acc=0.504    train_max_score=0.419 test_max_score=0.497   q_10=0.988 size_10=9.4 q_20=0.964 size_20=4.4 q_30=0.921 size_30=2.4
round_idx=16: train_acc=0.629 test_acc=0.506    train_max_score=0.431 test_max_score=0.500   q_10=0.989 size_10=9.5 q_20=0.963 size_20=4.3 q_30=0.920 size_30=2.4
round_idx=17: train_acc=0.637 test_acc=0.510    train_max_score=0.442 test_max_score=0.503   q_10=0.989 size_10=9.5 q_20=0.963 size_20=4.2 q_30=0.917 size_30=2.3
round_idx=18: train_acc=0.646 test_acc=0.513    train_max_score=0.453 test_max_score=0.506   q_10=0.988 size_10=9.3 q_20=0.962 size_20=4.2 q_30=0.914 size_30=2.2
round_idx=19: train_acc=0.653 test_acc=0.516    train_max_score=0.462 test_max_score=0.509   q_10=0.988 size_10=9.1 q_20=0.962 size_20=4.1 q_30=0.911 size_30=2.2
round_idx=20: train_acc=0.660 test_acc=0.519    train_max_score=0.471 test_max_score=0.511   q_10=0.988 size_10=8.9 q_20=0.960 size_20=4.0 q_30=0.911 size_30=2.1
round_idx=21: train_acc=0.667 test_acc=0.522    train_max_score=0.480 test_max_score=0.514   q_10=0.987 size_10=8.7 q_20=0.959 size_20=3.9 q_30=0.911 size_30=2.1
round_idx=22: train_acc=0.674 test_acc=0.526    train_max_score=0.487 test_max_score=0.516   q_10=0.987 size_10=8.5 q_20=0.958 size_20=3.8 q_30=0.910 size_30=2.1
round_idx=23: train_acc=0.680 test_acc=0.529    train_max_score=0.495 test_max_score=0.518   q_10=0.987 size_10=8.3 q_20=0.957 size_20=3.7 q_30=0.910 size_30=2.1
round_idx=24: train_acc=0.687 test_acc=0.530    train_max_score=0.502 test_max_score=0.520   q_10=0.987 size_10=8.3 q_20=0.957 size_20=3.7 q_30=0.908 size_30=2.1
round_idx=25: train_acc=0.694 test_acc=0.532    train_max_score=0.509 test_max_score=0.522   q_10=0.987 size_10=8.3 q_20=0.957 size_20=3.7 q_30=0.907 size_30=2.0
round_idx=26: train_acc=0.700 test_acc=0.534    train_max_score=0.515 test_max_score=0.524   q_10=0.987 size_10=8.3 q_20=0.957 size_20=3.7 q_30=0.904 size_30=2.0
round_idx=27: train_acc=0.706 test_acc=0.535    train_max_score=0.521 test_max_score=0.526   q_10=0.987 size_10=8.2 q_20=0.957 size_20=3.7 q_30=0.903 size_30=2.0
round_idx=28: train_acc=0.712 test_acc=0.536    train_max_score=0.527 test_max_score=0.527   q_10=0.987 size_10=8.0 q_20=0.957 size_20=3.7 q_30=0.903 size_30=2.0
round_idx=29: train_acc=0.718 test_acc=0.538    train_max_score=0.533 test_max_score=0.529   q_10=0.986 size_10=7.8 q_20=0.957 size_20=3.6 q_30=0.903 size_30=2.0
round_idx=30: train_acc=0.723 test_acc=0.540    train_max_score=0.538 test_max_score=0.530   q_10=0.986 size_10=7.7 q_20=0.957 size_20=3.6 q_30=0.902 size_30=2.0
round_idx=31: train_acc=0.729 test_acc=0.542    train_max_score=0.543 test_max_score=0.532   q_10=0.986 size_10=7.6 q_20=0.957 size_20=3.6 q_30=0.900 size_30=1.9
round_idx=32: train_acc=0.734 test_acc=0.543    train_max_score=0.548 test_max_score=0.533   q_10=0.986 size_10=7.7 q_20=0.956 size_20=3.6 q_30=0.899 size_30=1.9
round_idx=33: train_acc=0.739 test_acc=0.544    train_max_score=0.553 test_max_score=0.534   q_10=0.986 size_10=7.7 q_20=0.956 size_20=3.6 q_30=0.898 size_30=1.9
round_idx=34: train_acc=0.744 test_acc=0.546    train_max_score=0.557 test_max_score=0.535   q_10=0.986 size_10=7.6 q_20=0.956 size_20=3.6 q_30=0.896 size_30=1.9
round_idx=35: train_acc=0.750 test_acc=0.547    train_max_score=0.562 test_max_score=0.537   q_10=0.986 size_10=7.6 q_20=0.956 size_20=3.6 q_30=0.895 size_30=1.9
round_idx=36: train_acc=0.755 test_acc=0.548    train_max_score=0.566 test_max_score=0.538   q_10=0.986 size_10=7.6 q_20=0.956 size_20=3.5 q_30=0.893 size_30=1.8
round_idx=37: train_acc=0.760 test_acc=0.549    train_max_score=0.571 test_max_score=0.539   q_10=0.986 size_10=7.5 q_20=0.955 size_20=3.5 q_30=0.892 size_30=1.8
round_idx=38: train_acc=0.765 test_acc=0.550    train_max_score=0.575 test_max_score=0.540   q_10=0.986 size_10=7.4 q_20=0.955 size_20=3.5 q_30=0.890 size_30=1.8
round_idx=39: train_acc=0.771 test_acc=0.551    train_max_score=0.579 test_max_score=0.541   q_10=0.985 size_10=7.4 q_20=0.955 size_20=3.4 q_30=0.890 size_30=1.8
round_idx=40: train_acc=0.775 test_acc=0.552    train_max_score=0.582 test_max_score=0.542   q_10=0.985 size_10=7.4 q_20=0.954 size_20=3.4 q_30=0.889 size_30=1.8
round_idx=41: train_acc=0.781 test_acc=0.553    train_max_score=0.586 test_max_score=0.543   q_10=0.986 size_10=7.4 q_20=0.954 size_20=3.4 q_30=0.890 size_30=1.8
round_idx=42: train_acc=0.785 test_acc=0.554    train_max_score=0.590 test_max_score=0.543   q_10=0.986 size_10=7.4 q_20=0.953 size_20=3.3 q_30=0.889 size_30=1.8
round_idx=43: train_acc=0.789 test_acc=0.554    train_max_score=0.593 test_max_score=0.544   q_10=0.986 size_10=7.4 q_20=0.954 size_20=3.4 q_30=0.887 size_30=1.8
round_idx=44: train_acc=0.793 test_acc=0.555    train_max_score=0.597 test_max_score=0.545   q_10=0.986 size_10=7.4 q_20=0.953 size_20=3.3 q_30=0.887 size_30=1.8
round_idx=45: train_acc=0.797 test_acc=0.556    train_max_score=0.600 test_max_score=0.546   q_10=0.986 size_10=7.4 q_20=0.952 size_20=3.3 q_30=0.886 size_30=1.7
round_idx=46: train_acc=0.801 test_acc=0.557    train_max_score=0.604 test_max_score=0.546   q_10=0.985 size_10=7.3 q_20=0.952 size_20=3.3 q_30=0.885 size_30=1.7
round_idx=47: train_acc=0.805 test_acc=0.558    train_max_score=0.607 test_max_score=0.547   q_10=0.986 size_10=7.3 q_20=0.952 size_20=3.3 q_30=0.884 size_30=1.7
round_idx=48: train_acc=0.808 test_acc=0.559    train_max_score=0.610 test_max_score=0.548   q_10=0.986 size_10=7.3 q_20=0.952 size_20=3.2 q_30=0.883 size_30=1.7
round_idx=49: train_acc=0.812 test_acc=0.559    train_max_score=0.613 test_max_score=0.548   q_10=0.985 size_10=7.2 q_20=0.952 size_20=3.2 q_30=0.882 size_30=1.7
round_idx=50: train_acc=0.815 test_acc=0.560    train_max_score=0.616 test_max_score=0.549   q_10=0.985 size_10=7.1 q_20=0.952 size_20=3.2 q_30=0.881 size_30=1.7
round_idx=51: train_acc=0.819 test_acc=0.560    train_max_score=0.619 test_max_score=0.550   q_10=0.985 size_10=7.1 q_20=0.951 size_20=3.2 q_30=0.881 size_30=1.7
round_idx=52: train_acc=0.822 test_acc=0.561    train_max_score=0.622 test_max_score=0.550   q_10=0.985 size_10=7.1 q_20=0.950 size_20=3.1 q_30=0.882 size_30=1.7
round_idx=53: train_acc=0.826 test_acc=0.561    train_max_score=0.625 test_max_score=0.551   q_10=0.985 size_10=7.0 q_20=0.950 size_20=3.2 q_30=0.882 size_30=1.7
round_idx=54: train_acc=0.830 test_acc=0.562    train_max_score=0.628 test_max_score=0.551   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.2 q_30=0.881 size_30=1.7
round_idx=55: train_acc=0.832 test_acc=0.562    train_max_score=0.631 test_max_score=0.552   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.2 q_30=0.881 size_30=1.7
round_idx=56: train_acc=0.836 test_acc=0.562    train_max_score=0.633 test_max_score=0.552   q_10=0.985 size_10=7.0 q_20=0.949 size_20=3.1 q_30=0.881 size_30=1.7
round_idx=57: train_acc=0.838 test_acc=0.563    train_max_score=0.636 test_max_score=0.553   q_10=0.985 size_10=7.0 q_20=0.950 size_20=3.1 q_30=0.881 size_30=1.7
round_idx=58: train_acc=0.841 test_acc=0.564    train_max_score=0.639 test_max_score=0.553   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.1 q_30=0.881 size_30=1.7
round_idx=59: train_acc=0.844 test_acc=0.564    train_max_score=0.641 test_max_score=0.553   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.1 q_30=0.879 size_30=1.7
round_idx=60: train_acc=0.847 test_acc=0.564    train_max_score=0.644 test_max_score=0.554   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.1 q_30=0.879 size_30=1.7
round_idx=61: train_acc=0.850 test_acc=0.564    train_max_score=0.646 test_max_score=0.554   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=62: train_acc=0.853 test_acc=0.565    train_max_score=0.649 test_max_score=0.555   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.2 q_30=0.880 size_30=1.7
round_idx=63: train_acc=0.856 test_acc=0.565    train_max_score=0.651 test_max_score=0.555   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.2 q_30=0.880 size_30=1.7
round_idx=64: train_acc=0.859 test_acc=0.566    train_max_score=0.654 test_max_score=0.555   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.2 q_30=0.880 size_30=1.7
round_idx=65: train_acc=0.862 test_acc=0.566    train_max_score=0.656 test_max_score=0.556   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=66: train_acc=0.865 test_acc=0.567    train_max_score=0.658 test_max_score=0.556   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=67: train_acc=0.867 test_acc=0.567    train_max_score=0.661 test_max_score=0.556   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=68: train_acc=0.870 test_acc=0.568    train_max_score=0.663 test_max_score=0.557   q_10=0.985 size_10=7.0 q_20=0.951 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=69: train_acc=0.872 test_acc=0.568    train_max_score=0.665 test_max_score=0.557   q_10=0.985 size_10=6.9 q_20=0.951 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=70: train_acc=0.874 test_acc=0.569    train_max_score=0.667 test_max_score=0.557   q_10=0.985 size_10=6.9 q_20=0.950 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=71: train_acc=0.877 test_acc=0.570    train_max_score=0.669 test_max_score=0.558   q_10=0.985 size_10=6.9 q_20=0.950 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=72: train_acc=0.879 test_acc=0.570    train_max_score=0.672 test_max_score=0.558   q_10=0.985 size_10=6.9 q_20=0.951 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=73: train_acc=0.881 test_acc=0.571    train_max_score=0.674 test_max_score=0.558   q_10=0.985 size_10=6.9 q_20=0.950 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=74: train_acc=0.884 test_acc=0.571    train_max_score=0.676 test_max_score=0.558   q_10=0.985 size_10=6.9 q_20=0.950 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=75: train_acc=0.886 test_acc=0.572    train_max_score=0.678 test_max_score=0.559   q_10=0.985 size_10=6.9 q_20=0.949 size_20=3.1 q_30=0.880 size_30=1.7
round_idx=76: train_acc=0.888 test_acc=0.572    train_max_score=0.680 test_max_score=0.559   q_10=0.985 size_10=7.0 q_20=0.949 size_20=3.0 q_30=0.878 size_30=1.7
round_idx=77: train_acc=0.890 test_acc=0.573    train_max_score=0.682 test_max_score=0.559   q_10=0.985 size_10=7.0 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=78: train_acc=0.892 test_acc=0.573    train_max_score=0.684 test_max_score=0.559   q_10=0.985 size_10=7.0 q_20=0.948 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=79: train_acc=0.894 test_acc=0.574    train_max_score=0.686 test_max_score=0.560   q_10=0.985 size_10=6.9 q_20=0.948 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=80: train_acc=0.897 test_acc=0.574    train_max_score=0.688 test_max_score=0.560   q_10=0.985 size_10=6.9 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=81: train_acc=0.899 test_acc=0.575    train_max_score=0.690 test_max_score=0.560   q_10=0.985 size_10=6.9 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=82: train_acc=0.901 test_acc=0.575    train_max_score=0.692 test_max_score=0.560   q_10=0.985 size_10=6.9 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=83: train_acc=0.903 test_acc=0.575    train_max_score=0.694 test_max_score=0.560   q_10=0.985 size_10=6.9 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=84: train_acc=0.905 test_acc=0.575    train_max_score=0.695 test_max_score=0.561   q_10=0.985 size_10=6.9 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=85: train_acc=0.907 test_acc=0.575    train_max_score=0.697 test_max_score=0.561   q_10=0.985 size_10=6.9 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=86: train_acc=0.909 test_acc=0.575    train_max_score=0.699 test_max_score=0.561   q_10=0.985 size_10=6.9 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=87: train_acc=0.910 test_acc=0.575    train_max_score=0.701 test_max_score=0.561   q_10=0.985 size_10=7.0 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=88: train_acc=0.912 test_acc=0.575    train_max_score=0.703 test_max_score=0.561   q_10=0.985 size_10=7.0 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=89: train_acc=0.913 test_acc=0.575    train_max_score=0.705 test_max_score=0.561   q_10=0.985 size_10=7.0 q_20=0.949 size_20=3.0 q_30=0.877 size_30=1.6
round_idx=90: train_acc=0.915 test_acc=0.575    train_max_score=0.706 test_max_score=0.562   q_10=0.985 size_10=7.0 q_20=0.949 size_20=3.0 q_30=0.877 size_30=1.6
round_idx=91: train_acc=0.917 test_acc=0.575    train_max_score=0.708 test_max_score=0.562   q_10=0.985 size_10=7.0 q_20=0.949 size_20=3.0 q_30=0.877 size_30=1.6
round_idx=92: train_acc=0.918 test_acc=0.576    train_max_score=0.710 test_max_score=0.562   q_10=0.985 size_10=7.0 q_20=0.949 size_20=3.0 q_30=0.877 size_30=1.6
round_idx=93: train_acc=0.921 test_acc=0.576    train_max_score=0.712 test_max_score=0.562   q_10=0.985 size_10=7.0 q_20=0.949 size_20=3.0 q_30=0.877 size_30=1.6
round_idx=94: train_acc=0.922 test_acc=0.576    train_max_score=0.713 test_max_score=0.562   q_10=0.985 size_10=7.0 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=95: train_acc=0.924 test_acc=0.576    train_max_score=0.715 test_max_score=0.562   q_10=0.985 size_10=6.9 q_20=0.949 size_20=3.0 q_30=0.876 size_30=1.6
round_idx=96: train_acc=0.926 test_acc=0.576    train_max_score=0.717 test_max_score=0.562   q_10=0.985 size_10=6.9 q_20=0.949 size_20=3.0 q_30=0.877 size_30=1.6
round_idx=97: train_acc=0.928 test_acc=0.576    train_max_score=0.718 test_max_score=0.563   q_10=0.985 size_10=6.9 q_20=0.949 size_20=3.0 q_30=0.877 size_30=1.6
round_idx=98: train_acc=0.929 test_acc=0.576    train_max_score=0.720 test_max_score=0.563   q_10=0.985 size_10=6.9 q_20=0.950 size_20=3.0 q_30=0.877 size_30=1.6
round_idx=99: train_acc=0.931 test_acc=0.576    train_max_score=0.722 test_max_score=0.563   q_10=0.985 size_10=6.9 q_20=0.950 size_20=3.1 q_30=0.877 size_30=1.6
round_idx=100: train_acc=0.932 test_acc=0.576    train_max_score=0.723 test_max_score=0.563   q_10=0.985 size_10=6.9 q_20=0.950 size_20=3.1 q_30=0.878 size_30=1.6
 Finished TCT Stage-2 
==========total runtime 43732===========
